{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "INF0618_Aula05_TransferLearningResNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy2rO8CD2fzd"
      },
      "source": [
        "# Transfer Learning\n",
        "\n",
        "Neste exemplo, usaremos os pesos da ***ResNet50***, pré-treinados no conjunto ImageNet, para classificação das imagens do CIFAR-10. A expectativa é de que os filtros da rede que foram pré-treinados auxiliem na tarefa de classificação, por mais que as distribuições dos dados sejam diferentes. \n",
        "Faremos dois experimentos:\n",
        "\n",
        "1. Usar a rede como extrator de características, descartando a saída original e congelando suas as camadas. Adicionaremos uma nova camada de saída com o número de classes do CIFAR-10.\n",
        "\n",
        "2. Após este primeiro treinamento, vamos descongelar as camadas e fazer o _fine-tuning_ das camadas. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2EjL8tV2fzk"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "#Utility to plot\n",
        "def plotImages(imgList, n_row=1, n_col=1):\n",
        "    _, axs = plt.subplots(n_row, n_col, figsize=(3, 3))\n",
        "    axs = axs.flatten()\n",
        "    for img, ax in zip(imgList, axs):\n",
        "        ax.imshow(np.uint8(img), interpolation='nearest')\n",
        "    plt.show()\n",
        "        \n",
        "        \n",
        "def plotImage(img):\n",
        "    fig = plt.figure(figsize=(3,3))\n",
        "    ax = fig.add_subplot(111)\n",
        "\n",
        "    ax.imshow(np.uint8(img), interpolation='nearest')\n",
        "    plt.show()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWwtLHP-2fzy"
      },
      "source": [
        "## CIFAR-10\n",
        "\n",
        "Conjunto de dados composto de 60.000 imagens coloridas de dimensões 32x32, divididas em 10 classes (com 6.000 imagens por classe), sendo 50.000 para treinamento e 10.000 para teste. As classes do CIFAR-10 são **aviões, automóveis, pássaros, gatos, alces, cachorros, sapos, cavalos, navios, caminhões.**\n",
        "\n",
        "O código abaixo carrega e transforma os dados de entrada para ficarem prontos para serem treinados/classificados pela sua rede. Os conjuntos de treino, validação e teste estão balanceados, portanto a acurácia já estará normalizada nos métodos do Keras. \n",
        "\n",
        "***Veja como pré-processamos os dados com a função do próprio modelo pré-treinado.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zC3Zx3IE2fz3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "261430a8-269d-4d80-f888-76f09aae925a"
      },
      "source": [
        "#Load data\n",
        "(trainVal_data, trainVal_label), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#Split trainVal data into train and val sets (already balanced)\n",
        "sss = StratifiedShuffleSplit(1, test_size=10000, random_state=0)\n",
        "for train_index, val_index in sss.split(trainVal_data, trainVal_label):\n",
        "    X_train, X_val = trainVal_data[train_index], trainVal_data[val_index]\n",
        "    y_train, y_val = trainVal_label[train_index], trainVal_label[val_index]\n",
        "\n",
        "#X_train = X_train.astype('float32')\n",
        "#X_val = X_val.astype('float32')\n",
        "#X_test = X_test.astype('float32')\n",
        "\n",
        "print(\"Dados de treino:\", X_train.shape)\n",
        "print(\"Dados de validação:\", X_val.shape)\n",
        "print(\"Dados de teste:\", X_test.shape)\n",
        "print()\n",
        "n_classes = 10\n",
        "\n",
        "Y_train = tf.keras.utils.to_categorical(y_train, n_classes)\n",
        "Y_val = tf.keras.utils.to_categorical(y_val, n_classes)\n",
        "Y_test = tf.keras.utils.to_categorical(y_test, n_classes)\n",
        "\n",
        "# Computa a distribuição de amostras por classe\n",
        "num_train_classes, _ = np.histogram(y_train, bins=np.arange(n_classes)+1)\n",
        "num_valid_classes, _ = np.histogram(y_val, bins=np.arange(n_classes)+1)\n",
        "num_test_classes, _ = np.histogram(y_test, bins=np.arange(n_classes)+1)\n",
        "\n",
        "print(\"Distribuição de amostras por classe:\")\n",
        "print(\" - treino:\", num_train_classes)\n",
        "print(\" - validação:\", num_valid_classes)\n",
        "print(\" - teste:\", num_test_classes)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados de treino: (40000, 32, 32, 3)\n",
            "Dados de validação: (10000, 32, 32, 3)\n",
            "Dados de teste: (10000, 32, 32, 3)\n",
            "\n",
            "Distribuição de amostras por classe:\n",
            " - treino: [4000 4000 4000 4000 4000 4000 4000 4000 4000]\n",
            " - validação: [1000 1000 1000 1000 1000 1000 1000 1000 1000]\n",
            " - teste: [1000 1000 1000 1000 1000 1000 1000 1000 1000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "Kg4iclNSYK5w",
        "outputId": "92c0cd66-f517-494d-c432-1a9066d6b336"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen_for_printing = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "datagen_resnet = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=[0.6, 1],\n",
        "    preprocessing_function=tf.keras.applications.resnet50.preprocess_input\n",
        "    )\n",
        "\n",
        "# datagen com preprocessing\n",
        "gerador_batches_resnet = datagen_resnet.flow(X_train, Y_train, shuffle=False, batch_size=64)\n",
        "batch_X_proc, batch_Y_proc = gerador_batches_resnet.next()\n",
        "\n",
        "gerador_batches_printing = datagen_for_printing.flow(X_train, Y_train, shuffle=False, batch_size=64)\n",
        "batch_X, batch_Y = gerador_batches_printing.next()\n",
        "\n",
        "print(batch_X_proc.shape, batch_Y_proc.shape)\n",
        "print(batch_X.shape, batch_Y.shape)\n",
        "print(\"imagens apenas com aumentações\")\n",
        "plotImages(batch_X[:2], 1, 2)\n",
        "\n",
        "print(\"imagens com aumentações + pré-processamento resnet\")\n",
        "plotImages(batch_X_proc[:2], 1, 2)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 32, 32, 3) (64, 10)\n",
            "(64, 32, 32, 3) (64, 10)\n",
            "imagens apenas com aumentações\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imagens com aumentações + pré-processamento resnet\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXshP8oD2f0e"
      },
      "source": [
        "## Congelar camadas\n",
        "\n",
        "Vamos pegar a saída da ResNet50 após todas as convoluções, congelar os pesos, e adicionar uma camada densa treinável para as novas classes do CIFAR-10. Podemos pensar nas camadas congeladas como extrator de características.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ubAM7yv2f0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbd4ea19-33dd-4068-c093-50ae895f6331"
      },
      "source": [
        "# Carregamento do modelo pré-treinado SEM as camadas densas (include_top = False)\n",
        "model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(32,32,3))\n",
        "model.summary()\n",
        "\n",
        "# Congela camadas pré-treinadas\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Insere novas camadas no fim da rede para classificação\n",
        "frozen_model = tf.keras.Sequential([\n",
        "  model,\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "frozen_model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 16, 16, 64)   256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 16, 16, 64)   0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 8, 8, 64)     4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 8, 8, 64)     0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 8, 8, 64)     0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 8, 8, 256)    16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 8, 8, 256)    0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 8, 8, 256)    0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 8, 8, 64)     0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 8, 8, 64)     0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 8, 8, 256)    0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 8, 8, 256)    0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 8, 8, 64)     16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 8, 8, 64)     0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 8, 8, 256)    1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 8, 8, 256)    0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 8, 8, 256)    0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 4, 4, 128)    32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 4, 4, 128)    0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 4, 4, 128)    0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 4, 4, 512)    131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 4, 4, 512)    0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 4, 4, 512)    0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 4, 4, 128)    0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 4, 4, 128)    0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 4, 4, 512)    0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 4, 4, 512)    0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 4, 4, 128)    0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 4, 4, 128)    0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 4, 4, 512)    0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 4, 4, 512)    0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 4, 4, 128)    65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 4, 4, 128)    0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 4, 4, 512)    2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 4, 4, 512)    0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 4, 4, 512)    0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 2, 2, 256)    131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 2, 2, 256)    0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 2, 2, 256)    0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 2, 2, 1024)   525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 2, 2, 1024)   0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 2, 2, 256)    0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 2, 2, 256)    0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 2, 2, 1024)   0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 2, 2, 1024)   0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 2, 2, 256)    0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 2, 2, 256)    0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 2, 2, 1024)   0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 2, 2, 1024)   0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 2, 2, 256)    0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 2, 2, 256)    0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 2, 2, 1024)   0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 2, 2, 1024)   0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 2, 2, 256)    0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 2, 2, 256)    0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 2, 2, 1024)   0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 2, 2, 1024)   0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 2, 2, 256)    262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 2, 2, 256)    0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 2, 2, 256)    590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 2, 2, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 2, 2, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 2, 2, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 2, 2, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 2, 2, 1024)   0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 2, 2, 1024)   0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 1, 1, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 1, 1, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 1, 1, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 1, 1, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 1, 1, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 1, 1, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 1, 1, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 1, 1, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 1, 1, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 1, 1, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 1, 1, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 1, 1, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 1, 1, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 1, 1, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 1, 1, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 1, 1, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 1, 1, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 1, 1, 2048)   0           conv5_block3_add[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Functional)        (None, 1, 1, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,608,202\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOuJoDeH2f0t"
      },
      "source": [
        "Vamos compilar e treinar o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV0SwFN-2f0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9f8b4ae-34b8-489e-9f66-b5cbdb1a0c1b"
      },
      "source": [
        "# Instancia um otimizador SGD, compila e treina o modelo completo\n",
        "sgd = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9, decay=0.001, nesterov=True)\n",
        "\n",
        "# Batches de treino e validação\n",
        "train_batches = datagen_resnet.flow(X_train, Y_train, shuffle=True, batch_size=64)\n",
        "val_batches = datagen_resnet.flow(X_val, Y_val, shuffle=True, batch_size=64)\n",
        "\n",
        "# Early Stopping\n",
        "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "frozen_model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "frozen_model.fit(train_batches, epochs=25, callbacks=[early],\n",
        "                  validation_data=val_batches)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "625/625 [==============================] - 53s 77ms/step - loss: 1.8680 - accuracy: 0.4945 - val_loss: 1.5811 - val_accuracy: 0.5283\n",
            "Epoch 2/25\n",
            "625/625 [==============================] - 46s 74ms/step - loss: 1.4308 - accuracy: 0.5525 - val_loss: 1.3865 - val_accuracy: 0.5570\n",
            "Epoch 3/25\n",
            "625/625 [==============================] - 46s 73ms/step - loss: 1.2913 - accuracy: 0.5749 - val_loss: 1.2953 - val_accuracy: 0.5753\n",
            "Epoch 4/25\n",
            "625/625 [==============================] - 46s 73ms/step - loss: 1.2426 - accuracy: 0.5828 - val_loss: 1.2576 - val_accuracy: 0.5766\n",
            "Epoch 5/25\n",
            "625/625 [==============================] - 46s 73ms/step - loss: 1.2047 - accuracy: 0.5909 - val_loss: 1.2320 - val_accuracy: 0.5911\n",
            "Epoch 6/25\n",
            "625/625 [==============================] - 47s 75ms/step - loss: 1.1704 - accuracy: 0.5982 - val_loss: 1.2046 - val_accuracy: 0.5892\n",
            "Epoch 7/25\n",
            "625/625 [==============================] - 46s 74ms/step - loss: 1.1400 - accuracy: 0.6079 - val_loss: 1.2126 - val_accuracy: 0.5831\n",
            "Epoch 8/25\n",
            "625/625 [==============================] - 46s 74ms/step - loss: 1.1291 - accuracy: 0.6061 - val_loss: 1.1695 - val_accuracy: 0.5985\n",
            "Epoch 9/25\n",
            "625/625 [==============================] - 46s 74ms/step - loss: 1.1174 - accuracy: 0.6143 - val_loss: 1.1740 - val_accuracy: 0.6016\n",
            "Epoch 10/25\n",
            "625/625 [==============================] - 46s 74ms/step - loss: 1.1149 - accuracy: 0.6122 - val_loss: 1.1704 - val_accuracy: 0.5956\n",
            "Epoch 11/25\n",
            "625/625 [==============================] - 46s 73ms/step - loss: 1.1085 - accuracy: 0.6133 - val_loss: 1.1628 - val_accuracy: 0.6011\n",
            "Epoch 12/25\n",
            "625/625 [==============================] - 46s 74ms/step - loss: 1.0945 - accuracy: 0.6174 - val_loss: 1.1557 - val_accuracy: 0.6000\n",
            "Epoch 13/25\n",
            "625/625 [==============================] - 46s 73ms/step - loss: 1.0930 - accuracy: 0.6189 - val_loss: 1.1390 - val_accuracy: 0.6037\n",
            "Epoch 14/25\n",
            "625/625 [==============================] - 46s 74ms/step - loss: 1.0813 - accuracy: 0.6202 - val_loss: 1.1322 - val_accuracy: 0.6062\n",
            "Epoch 15/25\n",
            "625/625 [==============================] - 46s 74ms/step - loss: 1.0823 - accuracy: 0.6204 - val_loss: 1.1520 - val_accuracy: 0.6040\n",
            "Epoch 16/25\n",
            "625/625 [==============================] - 46s 74ms/step - loss: 1.0790 - accuracy: 0.6222 - val_loss: 1.1432 - val_accuracy: 0.5988\n",
            "Epoch 17/25\n",
            "625/625 [==============================] - 46s 74ms/step - loss: 1.0725 - accuracy: 0.6243 - val_loss: 1.1335 - val_accuracy: 0.6094\n",
            "Epoch 18/25\n",
            "625/625 [==============================] - 46s 74ms/step - loss: 1.0697 - accuracy: 0.6266 - val_loss: 1.1142 - val_accuracy: 0.6120\n",
            "Epoch 19/25\n",
            "625/625 [==============================] - 47s 75ms/step - loss: 1.0715 - accuracy: 0.6249 - val_loss: 1.1212 - val_accuracy: 0.6149\n",
            "Epoch 20/25\n",
            "625/625 [==============================] - 47s 76ms/step - loss: 1.0661 - accuracy: 0.6255 - val_loss: 1.1324 - val_accuracy: 0.6080\n",
            "Epoch 21/25\n",
            "625/625 [==============================] - 47s 75ms/step - loss: 1.0592 - accuracy: 0.6296 - val_loss: 1.1031 - val_accuracy: 0.6155\n",
            "Epoch 22/25\n",
            "625/625 [==============================] - 46s 74ms/step - loss: 1.0567 - accuracy: 0.6319 - val_loss: 1.0920 - val_accuracy: 0.6189\n",
            "Epoch 23/25\n",
            "625/625 [==============================] - 47s 76ms/step - loss: 1.0601 - accuracy: 0.6288 - val_loss: 1.1214 - val_accuracy: 0.6066\n",
            "Epoch 24/25\n",
            "625/625 [==============================] - 47s 75ms/step - loss: 1.0581 - accuracy: 0.6304 - val_loss: 1.1257 - val_accuracy: 0.6113\n",
            "Epoch 25/25\n",
            "625/625 [==============================] - 47s 75ms/step - loss: 1.0517 - accuracy: 0.6300 - val_loss: 1.1215 - val_accuracy: 0.6104\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0d004d0f50>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wASinznb2f1A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd3bc23a-80a8-4817-ea0c-fbe2cc20aa5f"
      },
      "source": [
        "# Avalia o modelo na validação\n",
        "score = frozen_model.evaluate(val_batches,verbose=1)\n",
        "\n",
        "print('Valid loss:', score[0])\n",
        "print('Valid acc:', score[1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 10s 63ms/step - loss: 1.1167 - accuracy: 0.6095\n",
            "Valid loss: 1.1167011260986328\n",
            "Valid acc: 0.609499990940094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OntN2FXWHkM"
      },
      "source": [
        "## Modelo congelado como extrator de features\n",
        "\n",
        "Após carregar o modelo pré-treinado, podemos usá-lo como extrator de características, e treinar um SVM sobre a representação obtida."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8pUaDN9WY-Q"
      },
      "source": [
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "frozen_model = tf.keras.Sequential([\n",
        "  model,\n",
        "  tf.keras.layers.GlobalAveragePooling2D()\n",
        "])\n",
        "\n",
        "feats_train = frozen_model.predict(X_train)\n",
        "feats_val = frozen_model.predict(X_val)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1Ja1okRWZCh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f58826c-af58-4e69-d088-d99b4ee29075"
      },
      "source": [
        "print(feats_train.shape)\n",
        "\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "clf = MLPClassifier(random_state=1, max_iter=300).fit(feats_train, Y_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40000, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylxysHOn5ZK3",
        "outputId": "f5d6735e-4e0d-4a6c-8746-d049e02229db"
      },
      "source": [
        "acc_mlp = clf.score(feats_val, Y_val)\n",
        "print(\"ACC MLP:\", acc_mlp)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACC MLP: 0.4558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zG1QXnS2f1K"
      },
      "source": [
        "## Fine-tuning \n",
        "\n",
        "Vamos agora descongelar o modelo inteiro e realizar o _fine-tuning_ da rede para o CIFAR-10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om2c3Fgq2f1N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3076dbc5-8503-48f9-ba27-43587df4b326"
      },
      "source": [
        "for layer in model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "ft_model = tf.keras.Sequential([\n",
        "  model,\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])    \n",
        "    \n",
        "ft_model.summary() #Note o núúmero de paramêtros treináveis"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Functional)        (None, 1, 1, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,608,202\n",
            "Trainable params: 23,555,082\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o25W2Xde2f1Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89523a43-2163-40c8-f83b-f0d4ade4ccb6"
      },
      "source": [
        "# Compila e treina o modelo\n",
        "sgd = tf.keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
        "\n",
        "# Batches de treino e validação\n",
        "train_batches = datagen_resnet.flow(X_train, Y_train, shuffle=True, batch_size=64)\n",
        "val_batches = datagen_resnet.flow(X_val, Y_val, shuffle=True, batch_size=64)\n",
        "\n",
        "# Early Stopping\n",
        "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "ft_model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "ft_model.fit(train_batches, epochs=25, callbacks=[early],\n",
        "                  validation_data=val_batches)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "625/625 [==============================] - 92s 135ms/step - loss: 1.5328 - accuracy: 0.4869 - val_loss: 1.2031 - val_accuracy: 0.5988\n",
            "Epoch 2/25\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 1.0666 - accuracy: 0.6335 - val_loss: 0.9977 - val_accuracy: 0.6551\n",
            "Epoch 3/25\n",
            "625/625 [==============================] - 83s 133ms/step - loss: 0.9522 - accuracy: 0.6722 - val_loss: 0.8929 - val_accuracy: 0.6891\n",
            "Epoch 4/25\n",
            "625/625 [==============================] - 83s 133ms/step - loss: 0.8696 - accuracy: 0.6989 - val_loss: 0.9037 - val_accuracy: 0.6974\n",
            "Epoch 5/25\n",
            "625/625 [==============================] - 83s 132ms/step - loss: 0.8158 - accuracy: 0.7220 - val_loss: 0.8205 - val_accuracy: 0.7148\n",
            "Epoch 6/25\n",
            "625/625 [==============================] - 83s 133ms/step - loss: 0.7749 - accuracy: 0.7332 - val_loss: 0.8206 - val_accuracy: 0.7232\n",
            "Epoch 7/25\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.7922 - accuracy: 0.7272 - val_loss: 0.7626 - val_accuracy: 0.7303\n",
            "Epoch 8/25\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.7382 - accuracy: 0.7475 - val_loss: 0.7488 - val_accuracy: 0.7408\n",
            "Epoch 9/25\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.7045 - accuracy: 0.7559 - val_loss: 0.7334 - val_accuracy: 0.7506\n",
            "Epoch 10/25\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.6733 - accuracy: 0.7677 - val_loss: 0.7258 - val_accuracy: 0.7516\n",
            "Epoch 11/25\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.6515 - accuracy: 0.7741 - val_loss: 0.7102 - val_accuracy: 0.7544\n",
            "Epoch 12/25\n",
            "625/625 [==============================] - 84s 135ms/step - loss: 0.6278 - accuracy: 0.7841 - val_loss: 0.7063 - val_accuracy: 0.7581\n",
            "Epoch 13/25\n",
            "625/625 [==============================] - 84s 135ms/step - loss: 0.6115 - accuracy: 0.7874 - val_loss: 0.6557 - val_accuracy: 0.7743\n",
            "Epoch 14/25\n",
            "625/625 [==============================] - 85s 135ms/step - loss: 0.6013 - accuracy: 0.7905 - val_loss: 0.6814 - val_accuracy: 0.7667\n",
            "Epoch 15/25\n",
            "625/625 [==============================] - 84s 135ms/step - loss: 0.5975 - accuracy: 0.7937 - val_loss: 0.6544 - val_accuracy: 0.7753\n",
            "Epoch 16/25\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.5847 - accuracy: 0.7990 - val_loss: 0.6287 - val_accuracy: 0.7838\n",
            "Epoch 17/25\n",
            "625/625 [==============================] - 84s 135ms/step - loss: 0.5653 - accuracy: 0.8017 - val_loss: 0.6503 - val_accuracy: 0.7767\n",
            "Epoch 18/25\n",
            "625/625 [==============================] - 84s 135ms/step - loss: 0.5589 - accuracy: 0.8071 - val_loss: 0.6843 - val_accuracy: 0.7671\n",
            "Epoch 19/25\n",
            "625/625 [==============================] - 84s 134ms/step - loss: 0.5442 - accuracy: 0.8108 - val_loss: 0.6655 - val_accuracy: 0.7718\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0c1dc42610>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5ZiY-Hx2f1j"
      },
      "source": [
        "Finalmente, avalie o modelo final no conjunto de teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxet68nu2f1m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "371a6ad3-0200-4fcb-da6b-fcc7441b3304"
      },
      "source": [
        "score = ft_model.evaluate(val_batches,verbose=1)\n",
        "print('Val loss:', score[0])\n",
        "print('Val acc:', score[1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 10s 60ms/step - loss: 0.6469 - accuracy: 0.7813\n",
            "Val loss: 0.6468590497970581\n",
            "Val acc: 0.7813000082969666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omgO0IuapTo6",
        "outputId": "35b74aab-4fd1-43f6-95e1-e1af6796bcfb"
      },
      "source": [
        "test_batches = datagen_resnet.flow(X_test, Y_test, shuffle=True, batch_size=64)\n",
        "\n",
        "score_test = ft_model.evaluate(test_batches,verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test acc:', score[1])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 10s 62ms/step - loss: 0.6502 - accuracy: 0.7773\n",
            "Test loss: 0.6468590497970581\n",
            "Test acc: 0.7813000082969666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwznnjUCul8u"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    }
  ]
}